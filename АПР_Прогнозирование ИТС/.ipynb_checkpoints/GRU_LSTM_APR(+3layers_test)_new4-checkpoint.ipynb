{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "import time\n",
    "\n",
    "def generator(data, lookback, delay, min_index, max_index,\n",
    "              shuffle=False, batch_size=128, step=1):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(\n",
    "                min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows),\n",
    "                           lookback // step,\n",
    "                           data.shape[-1]))\n",
    "        targets = np.zeros((len(rows)))\n",
    "        for j, row in enumerate(rows):\n",
    "            \n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "   \n",
    "            samples[j] = data[indices]\n",
    "    \n",
    "            targets[j] = data[rows[j] + delay]\n",
    "        \n",
    "        yield samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_ITS_perday = pd.read_excel(r\"C:\\Users\\1\\Desktop\\Papka\\Прогнозирование ИТС\\Full_dataset_transformer_final.xlsx\")\n",
    "df_ITS_perday=df_ITS_perday[['ИТС']]\n",
    "# df_ITS_perday=df_ITS_perday.set_index('Data')\n",
    "display(df_ITS_perday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(df_ITS_perday, 'g')\n",
    "plt.title('Расчетное значение ИТС', fontsize=18)\n",
    "plt.xlabel('Samples', fontsize=18)\n",
    "plt.ylabel('Значение ИТС', fontsize=18)\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сначала необходимо разделить данные на 3 части (выборки): обучающую, валидационную и тестовую\n",
    "data_train, data_test = train_test_split(df_ITS_perday, test_size=0.8125, random_state=42, shuffle = False)\n",
    "data_train, data_valid = train_test_split(data_train, test_size=0.4, random_state=42, shuffle = False)\n",
    "\n",
    "display(data_train)\n",
    "display(data_test)\n",
    "display(data_valid)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(data_test)\n",
    "\n",
    "data_train_sc = scaler.transform(data_train)\n",
    "data_valid_sc = scaler.transform(data_valid)\n",
    "data_test_sc = scaler.transform(data_test)\n",
    "\n",
    "display(data_train_sc)\n",
    "display(data_test_sc)\n",
    "display(data_valid_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(data_train_sc, 'purple')\n",
    "plt.title('Normalized train data', fontsize=18)\n",
    "plt.xlabel('Samples', fontsize=18)\n",
    "plt.ylabel('Normalized ITS in pu', fontsize=18)\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(data_valid_sc, 'blue')\n",
    "plt.title('Normalized valid data', fontsize=18)\n",
    "plt.xlabel('Samples', fontsize=18)\n",
    "plt.ylabel('Normalized ITS in pu', fontsize=18)\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(data_test_sc, 'orange')\n",
    "plt.title('Normalized test data', fontsize=18)\n",
    "plt.xlabel('Samples', fontsize=18)\n",
    "plt.ylabel('Normalized ITS in pu', fontsize=18)\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback=730\n",
    "step=1\n",
    "delay=1\n",
    "\n",
    "train_generator = generator(data_train_sc, \n",
    "                            lookback=lookback, \n",
    "                            delay=delay, \n",
    "                            min_index=0, \n",
    "                            max_index=data_train_sc.size, \n",
    "                            shuffle=False, \n",
    "                            batch_size=128, \n",
    "                            step=step)\n",
    "valid_generator = generator(data_valid_sc, \n",
    "                            lookback=lookback, \n",
    "                            delay=delay,\n",
    "                            min_index=0, \n",
    "                            max_index=data_valid_sc.size, \n",
    "                            shuffle=False,  \n",
    "                            batch_size=128,\n",
    "                            step=step)\n",
    "test_generator = generator(data_test_sc, \n",
    "                           lookback=lookback,\n",
    "                           delay=delay,\n",
    "                           min_index=0,\n",
    "                           max_index=data_test_sc.size, \n",
    "                           shuffle=False, \n",
    "                           batch_size=3650,\n",
    "                           step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Запускаем генератор один раз и получаем из него выборки (признаки) и целевые значения\n",
    "samples, targets = next(test_generator)\n",
    "# Если повторно запускать генератор, то будут выдаваться новые значения\n",
    "samples_range = np.arange(0, samples.shape[0], 1)\n",
    "# Выборки имеют форму (размер пакета, размер окна с признаками, признаки)\n",
    "pred = samples[:,-1,0]\n",
    "r_squared = r2_score(y_true=targets, y_pred=pred)\n",
    "mae = mean_absolute_error(y_true=targets, y_pred=pred)\n",
    "r_squared_error = 'Коэффициент детерминации без привлечения МО - {}'\\\n",
    ".format(r_squared)\n",
    "print(r_squared_error)\n",
    "mean_abs_error = 'Средняя абсолютная ошибка для решения без привлечения МО - {}'\\\n",
    ".format(mae)\n",
    "print(mean_abs_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируем спрогнозированного и фактического временных рядов на одном графике\n",
    "fig1, ax1 = plt.subplots(figsize=(16,8), facecolor='w', edgecolor='k')\n",
    "ax1.set_title('Real and predicted time series no ML on test data', fontsize=18)\n",
    "ax1.plot(samples_range, targets[0:samples.shape[0]], 'r', label = 'Real')\n",
    "ax1.plot(samples_range, pred, 'g', label = 'Predicted')\n",
    "ax1.set_xlabel('Samples', fontsize=16)\n",
    "ax1.set_ylabel('Normalized ITS in pu', fontsize=16)\n",
    "ax1.legend(loc='best', fontsize='x-large', title=\"Data\", title_fontsize='x-large')\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение рекуррентной сети для прогнозирования временного ряда (GRU). Расчет коэффициента детерминации и средней абсолютной ошибки. Визуализация спрогнозированных и фактических временных рядов на одном графике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Создаем модель нейронной сети\n",
    "model = Sequential()\n",
    "# Слой рекуррентной нейронной сети\n",
    "model.add(GRU(32, return_sequences = True, input_shape = (None, data_train_sc.shape[-1])))\n",
    "# Добавляем второй слой рекуррентной нейронной сети\n",
    "model.add(GRU(32, activation = 'relu'))\n",
    "# Выходной полносвязанный слой\n",
    "model.add(Dense(1))\n",
    "# Статистика с архитектурой сети\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем макисмальное число эпох\n",
    "EPOCHS = 20\n",
    "# Создаем пустые списки для метрик качества\n",
    "r_squared_list_train_rnn2l = []\n",
    "r_squared_list_valid_rnn2l = []\n",
    "epochs_range = np.arange(1, EPOCHS+1, 1)\n",
    "start = time.time()\n",
    "model.compile(loss='mse', \n",
    "              optimizer = 'adam',\n",
    "              metrics=[r2_score],\n",
    "              run_eagerly=True)\n",
    "history = model.fit(train_generator, steps_per_epoch=100, epochs = EPOCHS,\n",
    "                    verbose = 0, validation_data = valid_generator, validation_steps=1)\n",
    "# Обучаем модель Recurrent neural network (2 rec layers)\n",
    "for epochs_val in epochs_range:\n",
    "    r_squared_list_train_rnn2l.append(history.history['r2_score'][epochs_val-1])\n",
    "    r_squared_list_valid_rnn2l.append(history.history['val_r2_score'][epochs_val-1])\n",
    "\n",
    "stop = time.time()\n",
    "result = 'Время работы модели Recurrent neural network (2 rec layers) - {} секунд'\\\n",
    ".format(stop - start)\n",
    "# Сводим значения метрик в таблицу\n",
    "matrix = np.matrix(np.c_[epochs_range, r_squared_list_train_rnn2l, r_squared_list_valid_rnn2l]) \n",
    "df_models = pd.DataFrame(data=matrix, columns=['n_epochs', 'train_r_squared', 'valid_r_squared'])\n",
    "# Определяем наибольшее значение r_squared\n",
    "best_r_squared = df_models['valid_r_squared'].max()\n",
    "# Определяем индекс соответствующий наибольшему значению r_squared\n",
    "best_index = df_models['valid_r_squared'].idxmax()\n",
    "max_r_squared_rnn2l = 'Наибольшее значение r_squared алгоритма Recurrent neural network (2 rec layers) для валидационной выборки - {}'\\\n",
    ".format(best_r_squared)\n",
    "optimum_n_epochs = 'Оптимальное значение числа эпох для модели Recurrent neural network (2 rec layers) - {}'\\\n",
    ".format(epochs_range[best_index])\n",
    "print(result)\n",
    "print(max_r_squared_rnn2l)\n",
    "print(optimum_n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируем метрики r_squared для Recurrent neural network (2 rec layers) для тренировочной и валидационной выборки\n",
    "fig1, ax1 = plt.subplots(figsize=(16,8), facecolor='w', edgecolor='k')\n",
    "ax1.set_title('R_squared (Recurrent neural network (2 rec layers))', fontsize=18)\n",
    "ax1.plot(epochs_range, r_squared_list_valid_rnn2l, 'r', label = 'Valid')\n",
    "ax1.plot(epochs_range, r_squared_list_train_rnn2l, 'g', label = 'Train')\n",
    "ax1.set_xlabel('Number of epochs in training', fontsize=16)\n",
    "ax1.set_ylabel('r_squared rate', fontsize=16)\n",
    "ax1.legend(loc='best', fontsize='x-large', title=\"Data\", title_fontsize='x-large')\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# По найденному оптимальному параметру обучаем новый классификатор по Recurrent neural network (2 rec layers)\n",
    "model.fit(train_generator, steps_per_epoch=100, epochs=epochs_range[best_index],\n",
    "          verbose=0, validation_data=test_generator, validation_steps=1, initial_epoch=epochs_range[best_index-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем итоговое качество модели Recurrent neural network (2 rec layers) на тестовых данных\n",
    "samples, targets = next(test_generator)\n",
    "pred = model.predict(samples)\n",
    "r_squared = r2_score(y_true=targets, y_pred=pred)\n",
    "mae = mean_absolute_error(y_true=targets, y_pred=pred)\n",
    "r_squared_error = 'Коэффициент детерминации для решения с Recurrent neural network (2 rec layers) - {}'\\\n",
    ".format(r_squared)\n",
    "print(r_squared_error)\n",
    "mean_abs_error = 'Средняя абсолютная ошибка для решения с Recurrent neural network (2 rec layers) - {}'\\\n",
    ".format(mae)\n",
    "print(mean_abs_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируем спрогнозированного и фактического временных рядов на одном графике\n",
    "fig1, ax1 = plt.subplots(figsize=(16,8), facecolor='w', edgecolor='k')\n",
    "ax1.set_title('Real and predicted time series (Recurrent neural network (2 rec layers))', fontsize=18)\n",
    "ax1.plot(samples_range, targets[0:samples.shape[0]], 'r', label = 'Real')\n",
    "ax1.plot(samples_range, pred, 'g', label = 'Predicted')\n",
    "ax1.set_xlabel('Samples', fontsize=16)\n",
    "ax1.set_ylabel('Normalized ITS in pu', fontsize=16)\n",
    "ax1.legend(loc='best', fontsize='x-large', title=\"Data\", title_fontsize='x-large')\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение рекуррентной сети для прогнозирования временного ряда (LSTM). Расчет коэффициента детерминации и средней абсолютной ошибки. Визуализация спрогнозированных и фактических временных рядов на одном графике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences = True, input_shape = (None, data_train_sc.shape[-1])))\n",
    "model.add(LSTM(32, activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем макисмальное число эпох\n",
    "EPOCHS = 20\n",
    "# Создаем пустые списки для метрик качества\n",
    "r_squared_list_train_rnn2lstm = []\n",
    "r_squared_list_valid_rnn2lstm = []\n",
    "epochs_range = np.arange(1, EPOCHS+1, 1)\n",
    "start = time.time()\n",
    "model.compile(loss='mse', \n",
    "              optimizer = 'adam',\n",
    "              metrics=[r2_score],\n",
    "              run_eagerly=True)\n",
    "history = model.fit(train_generator, steps_per_epoch=100, epochs = EPOCHS,\n",
    "                    verbose = 0, validation_data = valid_generator, validation_steps=1)\n",
    "\n",
    "for epochs_val in epochs_range:\n",
    "    r_squared_list_train_rnn2lstm.append(history.history['r2_score'][epochs_val-1])\n",
    "    r_squared_list_valid_rnn2lstm.append(history.history['val_r2_score'][epochs_val-1])\n",
    "\n",
    "stop = time.time()\n",
    "result = 'Время работы модели Recurrent neural network (2 rec layers, LSTM) - {} секунд'\\\n",
    ".format(stop - start)\n",
    "# Сводим значения метрик в таблицу\n",
    "matrix = np.matrix(np.c_[epochs_range, r_squared_list_train_rnn2lstm, r_squared_list_valid_rnn2lstm]) \n",
    "df_models = pd.DataFrame(data=matrix, columns=['n_epochs', 'train_r_squared', 'valid_r_squared'])\n",
    "# Определяем наибольшее значение r_squared\n",
    "best_r_squared = df_models['valid_r_squared'].max()\n",
    "# Определяем индекс соответствующий наибольшему значению r_squared\n",
    "best_index = df_models['valid_r_squared'].idxmax()\n",
    "max_r_squared_rnn2lstm = 'Наибольшее значение r_squared алгоритма Recurrent neural network (2 rec layers, LSTM) для валидационной выборки - {}'\\\n",
    ".format(best_r_squared)\n",
    "optimum_n_epochs = 'Оптимальное значение числа эпох для модели Recurrent neural network (2 rec layers, LSTM) - {}'\\\n",
    ".format(epochs_range[best_index])\n",
    "print(result)\n",
    "print(max_r_squared_rnn2lstm)\n",
    "print(optimum_n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(figsize=(16,8), facecolor='w', edgecolor='k')\n",
    "ax1.set_title('R_squared (Recurrent neural network (2 rec layers, LSTM))', fontsize=18)\n",
    "ax1.plot(epochs_range, r_squared_list_valid_rnn2lstm, 'r', label = 'Valid')\n",
    "ax1.plot(epochs_range, r_squared_list_train_rnn2lstm, 'g', label = 'Train')\n",
    "ax1.set_xlabel('Number of epochs in training', fontsize=16)\n",
    "ax1.set_ylabel('r_squared rate', fontsize=16)\n",
    "ax1.legend(loc='best', fontsize='x-large', title=\"Data\", title_fontsize='x-large')\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# По найденному оптимальному параметру обучаем новый классификатор по Recurrent neural network (2 rec layers, LSTM)\n",
    "model.fit(train_generator, steps_per_epoch=100, epochs=epochs_range[best_index],\n",
    "          verbose=0, validation_data=test_generator, validation_steps=1, initial_epoch=epochs_range[best_index-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем итоговое качество модели Recurrent neural network (2 rec layers, LSTM) на тестовых данных\n",
    "samples, targets = next(test_generator)\n",
    "pred = model.predict(samples)\n",
    "r_squared = r2_score(y_true=targets, y_pred=pred)\n",
    "mae = mean_absolute_error(y_true=targets, y_pred=pred)\n",
    "r_squared_error = 'Коэффициент детерминации для решения с Recurrent neural network (2 rec layers, LSTM) - {}'\\\n",
    ".format(r_squared)\n",
    "print(r_squared_error)\n",
    "mean_abs_error = 'Средняя абсолютная ошибка для решения с Recurrent neural network (2 rec layers, LSTM) - {}'\\\n",
    ".format(mae)\n",
    "print(mean_abs_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируем спрогнозированного и фактического временных рядов на одном графике\n",
    "fig1, ax1 = plt.subplots(figsize=(16,8), facecolor='w', edgecolor='k')\n",
    "ax1.set_title('Real and predicted time series (Recurrent neural network (2 rec layers, LSTM))', fontsize=18)\n",
    "ax1.plot(samples_range, targets[0:samples.shape[0]], 'r', label = 'Real')\n",
    "ax1.plot(samples_range, pred, 'g', label = 'Predicted')\n",
    "ax1.set_xlabel('Samples', fontsize=16)\n",
    "ax1.set_ylabel('Normalized ITS in pu', fontsize=16)\n",
    "ax1.legend(loc='best', fontsize='x-large', title=\"Data\", title_fontsize='x-large')\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение рекуррентной сети для прогнозирования временного ряда (GRU) с прореживанием. Расчет коэффициента детерминации и средней абсолютной ошибки. Визуализация спрогнозированных и фактических временных рядов на одном графике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(32, dropout = 0.1, recurrent_dropout = 0.5, return_sequences = True,\n",
    "              input_shape = (None, data_train_sc.shape[-1])))\n",
    "model.add(GRU(32, activation = 'relu', dropout = 0.1, recurrent_dropout = 0.5))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "r_squared_list_train_rnn2ldo = []\n",
    "r_squared_list_valid_rnn2ldo = []\n",
    "epochs_range = np.arange(1, EPOCHS+1, 1)\n",
    "start = time.time()\n",
    "model.compile(loss='mse', \n",
    "              optimizer = 'adam',\n",
    "              metrics=[r2_score],\n",
    "              run_eagerly=True)\n",
    "history = model.fit(train_generator, steps_per_epoch=100, epochs = EPOCHS,\n",
    "                    verbose = 0, validation_data = valid_generator, validation_steps=1)\n",
    "# Обучаем модель Recurrent neural network (2 rec layers)\n",
    "for epochs_val in epochs_range:\n",
    "    r_squared_list_train_rnn2ldo.append(history.history['r2_score'][epochs_val-1])\n",
    "    r_squared_list_valid_rnn2ldo.append(history.history['val_r2_score'][epochs_val-1])\n",
    "\n",
    "stop = time.time()\n",
    "result = 'Время работы модели Recurrent neural network (2 rec layers+do) - {} секунд'\\\n",
    ".format(stop - start)\n",
    "# Сводим значения метрик в таблицу\n",
    "matrix = np.matrix(np.c_[epochs_range, r_squared_list_train_rnn2ldo, r_squared_list_valid_rnn2ldo]) \n",
    "df_models = pd.DataFrame(data=matrix, columns=['n_epochs', 'train_r_squared', 'valid_r_squared'])\n",
    "# Определяем наибольшее значение r_squared\n",
    "best_r_squared = df_models['valid_r_squared'].max()\n",
    "# Определяем индекс соответствующий наибольшему значению r_squared\n",
    "best_index = df_models['valid_r_squared'].idxmax()\n",
    "max_r_squared_rnn2ldo = 'Наибольшее значение r_squared алгоритма Recurrent neural network (2 rec layers+do) для валидационной выборки - {}'\\\n",
    ".format(best_r_squared)\n",
    "optimum_n_epochs = 'Оптимальное значение числа эпох для модели Recurrent neural network (2 rec layers+do) - {}'\\\n",
    ".format(epochs_range[best_index])\n",
    "print(result)\n",
    "print(max_r_squared_rnn2ldo)\n",
    "print(optimum_n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируем метрики r_squared для Recurrent neural network (2 rec layers+do) для тренировочной и валидационной выборки\n",
    "fig1, ax1 = plt.subplots(figsize=(16,8), facecolor='w', edgecolor='k')\n",
    "ax1.set_title('R_squared (Recurrent neural network (2 rec layers+do))', fontsize=18)\n",
    "ax1.plot(epochs_range, r_squared_list_valid_rnn2ldo, 'r', label = 'Valid')\n",
    "ax1.plot(epochs_range, r_squared_list_train_rnn2ldo, 'g', label = 'Train')\n",
    "ax1.set_xlabel('Number of epochs in training', fontsize=16)\n",
    "ax1.set_ylabel('r_squared rate', fontsize=16)\n",
    "ax1.legend(loc='best', fontsize='x-large', title=\"Data\", title_fontsize='x-large')\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# По найденному оптимальному параметру обучаем новый классификатор по Recurrent neural network (2 rec layers+do)\n",
    "model.fit(train_generator, steps_per_epoch=100, epochs=epochs_range[best_index],\n",
    "          verbose=0, validation_data=test_generator, validation_steps=1, initial_epoch=epochs_range[best_index-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем итоговое качество модели Recurrent neural network (2 rec layers+do) на тестовых данных\n",
    "samples, targets = next(test_generator)\n",
    "pred = model.predict(samples)\n",
    "r_squared = r2_score(y_true=targets, y_pred=pred)\n",
    "mae = mean_absolute_error(y_true=targets, y_pred=pred)\n",
    "r_squared_error = 'Коэффициент детерминации для решения с Recurrent neural network (2 rec layers+do) - {}'\\\n",
    ".format(r_squared)\n",
    "print(r_squared_error)\n",
    "mean_abs_error = 'Средняя абсолютная ошибка для решения с Recurrent neural network (2 rec layers+do) - {}'\\\n",
    ".format(mae)\n",
    "print(mean_abs_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируем спрогнозированного и фактического временных рядов на одном графике\n",
    "fig1, ax1 = plt.subplots(figsize=(16,8), facecolor='w', edgecolor='k')\n",
    "ax1.set_title('Real and predicted time series (Recurrent neural network (2 rec layers+do))', fontsize=18)\n",
    "ax1.plot(samples_range, targets[0:samples.shape[0]], 'r', label = 'Real')\n",
    "ax1.plot(samples_range, pred, 'g', label = 'Predicted')\n",
    "ax1.set_xlabel('Samples', fontsize=16)\n",
    "ax1.set_ylabel('Normalized ITS in pu', fontsize=16)\n",
    "ax1.legend(loc='best', fontsize='x-large', title=\"Data\", title_fontsize='x-large')\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение рекуррентной сети для прогнозирования временного ряда (LSTM) с тремя слоями. Расчет коэффициента детерминации и средней абсолютной ошибки. Визуализация спрогнозированных и фактических временных рядов на одном графике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences = True, input_shape = (None, data_train_sc.shape[-1])))\n",
    "model.add(LSTM(32, return_sequences = True, activation = 'relu'))\n",
    "model.add(LSTM(32, activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "r_squared_list_train_rnn3l = []\n",
    "r_squared_list_valid_rnn3l = []\n",
    "epochs_range = np.arange(1, EPOCHS+1, 1)\n",
    "start = time.time()\n",
    "model.compile(loss='mse', \n",
    "              optimizer = 'adam',\n",
    "              metrics=[r2_score],\n",
    "              run_eagerly=True)\n",
    "history = model.fit(train_generator, steps_per_epoch=100, epochs = EPOCHS,\n",
    "                    verbose = 0, validation_data = valid_generator, validation_steps=1)\n",
    "# Обучаем модель Recurrent neural network (3 rec layers)\n",
    "for epochs_val in epochs_range:\n",
    "    r_squared_list_train_rnn3l.append(history.history['r2_score'][epochs_val-1])\n",
    "    r_squared_list_valid_rnn3l.append(history.history['val_r2_score'][epochs_val-1])\n",
    "\n",
    "stop = time.time()\n",
    "result = 'Время работы модели Recurrent neural network (3 rec layers, LSTM) - {} секунд'\\\n",
    ".format(stop - start)\n",
    "# Сводим значения метрик в таблицу\n",
    "matrix = np.matrix(np.c_[epochs_range, r_squared_list_train_rnn3l, r_squared_list_valid_rnn3l]) \n",
    "df_models = pd.DataFrame(data=matrix, columns=['n_epochs', 'train_r_squared', 'valid_r_squared'])\n",
    "# Определяем наибольшее значение r_squared\n",
    "best_r_squared = df_models['valid_r_squared'].max()\n",
    "# Определяем индекс соответствующий наибольшему значению r_squared\n",
    "best_index = df_models['valid_r_squared'].idxmax()\n",
    "max_r_squared_rnn3l = 'Наибольшее значение r_squared алгоритма Recurrent neural network (3 rec layers, LSTM) для валидационной выборки - {}'\\\n",
    ".format(best_r_squared)\n",
    "optimum_n_epochs = 'Оптимальное значение числа эпох для модели Recurrent neural network (3 rec layers, LSTM) - {}'\\\n",
    ".format(epochs_range[best_index])\n",
    "print(result)\n",
    "print(max_r_squared_rnn3l)\n",
    "print(optimum_n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируем метрики r_squared для Recurrent neural network (3 rec layers, GRU) для тренировочной и валидационной выборки\n",
    "fig1, ax1 = plt.subplots(figsize=(16,8), facecolor='w', edgecolor='k')\n",
    "ax1.set_title('R_squared (Recurrent neural network (3 rec layers, LSTM))', fontsize=18)\n",
    "ax1.plot(epochs_range, r_squared_list_valid_rnn3l, 'r', label = 'Valid')\n",
    "ax1.plot(epochs_range, r_squared_list_train_rnn3l, 'g', label = 'Train')\n",
    "ax1.set_xlabel('Number of epochs in training', fontsize=16)\n",
    "ax1.set_ylabel('r_squared rate', fontsize=16)\n",
    "ax1.legend(loc='best', fontsize='x-large', title=\"Data\", title_fontsize='x-large')\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# По найденному оптимальному параметру обучаем новый классификатор по Recurrent neural network (3 rec layers, LSTM)\n",
    "model.fit(train_generator, steps_per_epoch=100, epochs=epochs_range[best_index],\n",
    "          verbose=0, validation_data=train_generator, validation_steps=1, initial_epoch=epochs_range[best_index-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем итоговое качество модели Recurrent neural network (3 rec layers, LSTM) на тестовых данных\n",
    "samples, targets = next(test_generator)\n",
    "pred = model.predict(samples)\n",
    "r_squared = r2_score(y_true=targets, y_pred=pred)\n",
    "mae = mean_absolute_error(y_true=targets, y_pred=pred)\n",
    "r_squared_error = 'Коэффициент детерминации для решения с Recurrent neural network (3 rec layers, LSTM) - {}'\\\n",
    ".format(r_squared)\n",
    "print(r_squared_error)\n",
    "mean_abs_error = 'Средняя абсолютная ошибка для решения с Recurrent neural network (3 rec layers, LSTM) - {}'\\\n",
    ".format(mae)\n",
    "print(mean_abs_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируем спрогнозированного и фактического временных рядов на одном графике\n",
    "fig1, ax1 = plt.subplots(figsize=(16,8), facecolor='w', edgecolor='k')\n",
    "ax1.set_title('Real and predicted time series (Recurrent neural network (3 rec layers, LSTM))', fontsize=18)\n",
    "ax1.plot(samples_range, targets[0:samples.shape[0]], 'r', label = 'Real')\n",
    "ax1.plot(samples_range, pred, 'g', label = 'Predicted')\n",
    "ax1.set_xlabel('Samples', fontsize=16)\n",
    "ax1.set_ylabel('Normalized ITS in pu', fontsize=16)\n",
    "ax1.legend(loc='best', fontsize='x-large', title=\"Data\", title_fontsize='x-large')\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение рекуррентной сети для прогнозирования временного ряда (GRU) с тремя слоями. Расчет коэффициента детерминации и средней абсолютной ошибки. Визуализация спрогнозированных и фактических временных рядов на одном графике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(32, return_sequences = True, input_shape = (None, data_train_sc.shape[-1])))\n",
    "model.add(GRU(32, return_sequences = True, activation = 'relu'))\n",
    "model.add(GRU(32, activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "r_squared_list_train_rnn3lg = []\n",
    "r_squared_list_valid_rnn3lg = []\n",
    "epochs_range = np.arange(1, EPOCHS+1, 1)\n",
    "start = time.time()\n",
    "model.compile(loss='mse', \n",
    "              optimizer = 'adam',\n",
    "              metrics=[r2_score],\n",
    "              run_eagerly=True)\n",
    "history = model.fit(train_generator, steps_per_epoch=100, epochs = EPOCHS,\n",
    "                    verbose = 0, validation_data = valid_generator, validation_steps=1)\n",
    "# Обучаем модель Recurrent neural network (3 rec layers)\n",
    "for epochs_val in epochs_range:\n",
    "    r_squared_list_train_rnn3lg.append(history.history['r2_score'][epochs_val-1])\n",
    "    r_squared_list_valid_rnn3lg.append(history.history['val_r2_score'][epochs_val-1])\n",
    "\n",
    "stop = time.time()\n",
    "result = 'Время работы модели Recurrent neural network (3 rec layers, GRU) - {} секунд'\\\n",
    ".format(stop - start)\n",
    "# Сводим значения метрик в таблицу\n",
    "matrix = np.matrix(np.c_[epochs_range, r_squared_list_train_rnn3lg, r_squared_list_valid_rnn3lg]) \n",
    "df_models = pd.DataFrame(data=matrix, columns=['n_epochs', 'train_r_squared', 'valid_r_squared'])\n",
    "# Определяем наибольшее значение r_squared\n",
    "best_r_squared = df_models['valid_r_squared'].max()\n",
    "# Определяем индекс соответствующий наибольшему значению r_squared\n",
    "best_index = df_models['valid_r_squared'].idxmax()\n",
    "max_r_squared_rnn3lg = 'Наибольшее значение r_squared алгоритма Recurrent neural network (3 rec layers, GRU) для валидационной выборки - {}'\\\n",
    ".format(best_r_squared)\n",
    "optimum_n_epochs = 'Оптимальное значение числа эпох для модели Recurrent neural network (3 rec layers, GRU) - {}'\\\n",
    ".format(epochs_range[best_index])\n",
    "print(result)\n",
    "print(max_r_squared_rnn3lg)\n",
    "print(optimum_n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируем метрики r_squared для Recurrent neural network (3 rec layers, GRU) для тренировочной и валидационной выборки\n",
    "fig1, ax1 = plt.subplots(figsize=(16,8), facecolor='w', edgecolor='k')\n",
    "ax1.set_title('R_squared (Recurrent neural network (3 rec layers, GRU))', fontsize=18)\n",
    "ax1.plot(epochs_range, r_squared_list_valid_rnn3lg, 'r', label = 'Valid')\n",
    "ax1.plot(epochs_range, r_squared_list_train_rnn3lg, 'g', label = 'Train')\n",
    "ax1.set_xlabel('Number of epochs in training', fontsize=16)\n",
    "ax1.set_ylabel('r_squared rate', fontsize=16)\n",
    "ax1.legend(loc='best', fontsize='x-large', title=\"Data\", title_fontsize='x-large')\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# По найденному оптимальному параметру обучаем новый классификатор по Recurrent neural network (3 rec layers, GRU)\n",
    "model.fit(train_generator, steps_per_epoch=100, epochs=epochs_range[best_index],\n",
    "          verbose=0, validation_data=test_generator, validation_steps=1, initial_epoch=epochs_range[best_index-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем итоговое качество модели Recurrent neural network (3 rec layers, GRU) на тестовых данных\n",
    "samples, targets = next(test_generator)\n",
    "pred = model.predict(samples)\n",
    "r_squared = r2_score(y_true=targets, y_pred=pred)\n",
    "mae = mean_absolute_error(y_true=targets, y_pred=pred)\n",
    "r_squared_error = 'Коэффициент детерминации для решения с Recurrent neural network (3 rec layers, GRU) - {}'\\\n",
    ".format(r_squared)\n",
    "print(r_squared_error)\n",
    "mean_abs_error = 'Средняя абсолютная ошибка для решения с Recurrent neural network (3 rec layers, GRU) - {}'\\\n",
    ".format(mae)\n",
    "print(mean_abs_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируем спрогнозированного и фактического временных рядов на одном графике\n",
    "fig1, ax1 = plt.subplots(figsize=(16,8), facecolor='w', edgecolor='k')\n",
    "ax1.set_title('Real and predicted time series (Recurrent neural network (3 rec layers, GRU))', fontsize=18)\n",
    "ax1.plot(samples_range, targets[0:samples.shape[0]], 'r', label = 'Real')\n",
    "ax1.plot(samples_range, pred, 'g', label = 'Predicted')\n",
    "ax1.set_xlabel('Samples', fontsize=16)\n",
    "ax1.set_ylabel('Normalized ITS in pu', fontsize=16)\n",
    "ax1.legend(loc='best', fontsize='x-large', title=\"Data\", title_fontsize='x-large')\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
    "                      target_size, step, single_step=False):\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i, step)\n",
    "    data.append(dataset[indices])\n",
    "\n",
    "    if single_step:\n",
    "      labels.append(target[i+target_size])\n",
    "    else:\n",
    "      labels.append(target[i:i+target_size])\n",
    "\n",
    "  return np.array(data), np.array(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
